version: '3.8'

services:
  # Service pour le nœud maître Hadoop
  hadoop-master:
    image: yassern1/hadoop-spark-jupyter:1.0.3
    container_name: hadoop-master
    hostname: hadoop-master
    networks:
      - hadoop
    ports:
      - "9870:9870" # NameNode Web UI
      - "8088:8088" # ResourceManager Web UI
      - "7077:7077" # Spark Master
      - "19888:19888" # MapReduce JobHistory Server
      - "8080:8080" # Jupyter Notebook (si présent)
      - "9000:9000" # HDFS Client Port (hdfs://hadoop-master:9000)
    volumes:
      # Le dossier local sur votre machine hôte doit exister avant de lancer compose
      # Remplacez /home/devops par votre nom d'utilisateur si différent
      - type: bind
        source: /home/devops/Documents/hadoop_project
        target: /shared_volume
    stdin_open: true
    tty: true
    command: >
      bash -c "
        echo 'Starting HDFS and YARN services directly on master...' &&
        # Démarrer HDFS (NameNode et SecondaryNameNode sur le master)
        $HADOOP_HOME/sbin/start-dfs.sh &&
        # Démarrer YARN (ResourceManager sur le master)
        $HADOOP_HOME/sbin/start-yarn.sh &&
        # Démarrer le JobHistoryServer
        $HADOOP_HOME/sbin/mr-jobhistory-daemon.sh start historyserver &&
        # Garde le conteneur actif
        tail -f /dev/null
      "
    depends_on:
      - hadoop-slave1
      - hadoop-slave2

  # Service pour le premier nœud esclave
  hadoop-slave1:
    image: yassern1/hadoop-spark-jupyter:1.0.3
    container_name: hadoop-slave1
    hostname: hadoop-slave1
    networks:
      - hadoop
    ports:
      - "8040:8042" # NodeManager Web UI (optionnel, vérifiez dans l'image)
    stdin_open: true
    tty: true
    command: >
      bash -c "
        echo 'Starting DataNode and NodeManager on slave1...' &&
        # Démarrer uniquement les services esclaves
        $HADOOP_HOME/sbin/hadoop-daemon.sh start datanode &&
        $HADOOP_HOME/sbin/yarn-daemon.sh start nodemanager &&
        # Garde le conteneur actif
        tail -f /dev/null
      "

  # Service pour le deuxième nœud esclave
  hadoop-slave2:
    image: yassern1/hadoop-spark-jupyter:1.0.3
    container_name: hadoop-slave2
    hostname: hadoop-slave2
    networks:
      - hadoop
    ports:
      - "8041:8042" # NodeManager Web UI (optionnel, vérifiez dans l'image)
    stdin_open: true
    tty: true
    command: >
      bash -c "
        echo 'Starting DataNode and NodeManager on slave2...' &&
        # Démarrer uniquement les services esclaves
        $HADOOP_HOME/sbin/hadoop-daemon.sh start datanode &&
        $HADOOP_HOME/sbin/yarn-daemon.sh start nodemanager &&
        # Garde le conteneur actif
        tail -f /dev/null
      "

networks:
  hadoop:
    driver: bridge

# Vérifiez que ce dossier existe sur votre machine hôte AVANT de lancer docker-compose
# mkdir -p /home/devops/Documents/hadoop_project
